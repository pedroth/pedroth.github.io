Differential Equations and Matrix exponential

In this post I would like to talk about simple differential equations in the euclidean space. Throughout this post let $n,m,k,N$ be integers. This is the problem of finding a function $\mathbf{x}:\mathbb{R}\rightarrow\mathbb{R}^n$ such that $\dot{\mathbf{x}}(t) = \frac{d \mathbf{x}}{dt} = \mathbf{g}(t,\mathbf{x})$. Which is the same as $$\dot{\mathbf{x}} = \begin{bmatrix}\dot{x}_1\\ ...\\ \dot{x}_n\end{bmatrix} = \begin{bmatrix}
g_1(t,x_1,...,x_n)\\...
\\ g_n(t,x_1,...,x_n)
\end{bmatrix} \;\;\;\;(1)$$

We have already seen some differential equations in the Taylor and differential calculus posts. If we simplify (1) we can easily solve it. Suppose we have the following equation $$\dot{\mathbf{x}}(t) = \mathbf{g}(t)\,\,\;\;\;\;(2)$$

To solve it you just need to use the fundamental theorem of calculus, like this:
 $$\mathbf{x}(t) = \mathbf{x}(0) + \int_0^{t} \dot{\mathbf{g}}(\tau) \,d\tau\;\;\;\;(3)$$

or if you want a more analytical expression, you could use the same approach as Taylor polynomial post:
Suppose we could compute all the derivatives at a point, then by using (3) we get:
 $$\mathbf{x}(t) = \mathbf{x}(0) + \int_0^{t} \dot{\mathbf{g}}(\tau) \,d\tau$$

note that $$\int_0^{t} \dot{\mathbf{g}}(\tau) \,d\tau = \begin{bmatrix}
\int_0^t \dot{g_1}(\tau)d\tau\\
...\\
\int_0^t \dot{g_n}(\tau)d\tau
\end{bmatrix}$$

And finally the Taylor polynomial

$$\mathbf{x}(t) = \mathbf{x}(0) + \int_0^{t} \dot{\mathbf{g}}(0) \,d\tau + \int_0^t\int_0^\tau\ddot{\mathbf{g}}(0) d\tau_2 \;+...$$
$$\mathbf{x}(t) = \mathbf{x}(0) + \sum_{k=1}^{\infty} \frac{d^{(k)}\mathbf{g}(0)}{dt} \frac{t^k}{k!}\;\;\;\;(4)$$

Now we have two ways to find a solution for (2), but what about (1)? In this post I will just solve a simpler version of (1), which is the following:

$$\dot{\mathbf{x}} =  M \mathbf{x}\;\;,\;\mathbf{x}(0) = \mathbf{x}_0\;\;\;\;(5)$$

where $M \in \mathbb{R}^{n\times n}$ is a n by n matrix. In order to solve (4) we will use the Taylor polynomial approach since we can not use (3) approach because (5) depends on $\mathbf{x}$ and $t$ and not only on $t$.

$$\frac{d\mathbf{x}}{dt} = M \mathbf{x}$$
$$\frac{d^2\mathbf{x}}{dt} = M \frac{d\mathbf{x}}{dt} = M^2 \mathbf{x}$$
$$...$$
$$\frac{d^k\mathbf{x}}{dt} = M^k \mathbf{x}\;\;\;\;(6)$$

Using the initial condition $\mathbf{x}(0) = \mathbf{x}_0$, (6) and (4) we get the solution.
$$\mathbf{x}(t) = \sum_{k=0}^{\infty} \frac{d^{(k)}\mathbf{x}(0)}{dt} \frac{t^k}{k!}$$
$$\Leftrightarrow \mathbf{x}(t)  =  \sum_{k=0}^{\infty} M^k \mathbf{x}_0 \frac{t^k}{k!}$$
$$\Leftrightarrow \mathbf{x}(t)  =  \left (\lim_{N \rightarrow \infty} \sum_{k=0}^{N}   \frac{(M t)^k}{k!}\right )\mathbf{x}_0\;\;\;\;(7)$$

And finally we have a way to compute $\mathbf{x}(t)$, (In order to compute we must choose $N$ high enough such that the sum converges).

To study this function little bit further, I will solve it using yet another technique, the Euler method. To explain the Euler method we need to see (5) as a vector field shown in fig 1 and 2.


fig 1


fig 2
A vector field is a function $\mathbf{F}(\mathbf{x})$ that attributes at each point in the space a vector. For instance our differential equation (5) can be seen as vector field $\mathbf{F}(\mathbf{x}) = M \mathbf{x}$.

e.g: $$\dot{\mathbf{x}} = \begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} \mathbf{x}$$ is the vector field on fig 1.

Now we are ready to solve (5) using the Euler method. The Euler method is a simple method which one could derive just by looking to fig 2. We start at an initial position $\mathbf{x}_0$ then we compute the tangent vector to the curve by computing the vector field function, after that we find the next position by following the tangent vector by a step $h>0$. This translates in the following iteration.
$$\mathbf{x}(t_0) = \mathbf{x}_0\\
\mathbf{x}(t + h) = \mathbf{x}(t) + h\mathbf{F}(\mathbf{x}(t))\;\;\;\;(8)$$

Using (8) in our simple ODE(ordinary differential equation) (5), we get

$$\mathbf{x}(t+h) = \mathbf{x}(t) + h M\mathbf{x}(t)\\
\Leftrightarrow   \mathbf{x}(t+h) = (I + h M)\mathbf{x}(t) \\$$

$$\mathbf{x}(t_0) = \mathbf{x}_0$$
$$\mathbf{x}(t_0 + h) = (I + h M)\mathbf{x}_0$$
$$\mathbf{x}(t_0 + 2h) = (I + h M)\mathbf{x}(t_0+h) = (I + h M)^2\mathbf{x}_0$$
$$...$$
$$\mathbf{x}(t_0 + nh) = (I + h M)^n\mathbf{x}_0\;\;\;(8.25)$$

This method is simple but comes with great cost, which is the error of the curve varies with $h$ (as $h$ increases the error increases), as you can see in fig 2 (red curve). In the limit of $h\rightarrow 0$ the curve generated by the Euler method converges to solution of the ODE.
Let $t = t_0 + nh$, where $n$ is the number of samples. Then $h = \frac{t - t_0}{n}$

From (8.25) and substituting $h$:

$$\mathbf{x}(t) = \lim_{n\to \infty}\left (I + \left (\frac{t-t_0}{n}\right )M \right )^{n}\mathbf{x}_0\;\;\;(8.5)$$

Let $t_0 = 0,\;\; t = 1$ ,(8.5) becomes :

$$\mathbf{x}(t) =\lim_{n\to \infty}\left (I + \left (\frac{1}{n}\right )M\right )^n\mathbf{x}_0$$

We can now define the matrix exponential as :

$$e^{M} =  \lim_{n\to \infty}\left (I + \left (\frac{1}{n}\right )M\right )^n$$

From (7) and (8) we can conclude that solution of (5) is
$$\mathbf{x}(t) = \left( \lim_{N \rightarrow \infty} \sum_{k=0}^{N}   \frac{(M (t-t_0))^k}{k!}\right)\mathbf{x}_0$$
$$\Leftrightarrow \mathbf{x}(t) =  \lim_{n \to \infty}\left (I + \left (\frac{t-t_0}{n}\right )M\right )^{n} \mathbf{x}_0$$

With the argument above we define the exponetial function as:

$$\exp\left (M(t-t_0), \mathbf{x_0} \right ) =  e^{M(t-t_0)}\mathbf{x}_0 = \mathbf{x}(t)$$

The solution to (5) is :

$$\mathbf{x}(t) =  e^{Mt} \mathbf{x}_0$$

Note that $t_0 = 0$ in (5).

To conclude lets check an example:
I will use fig 1 example which is $$\dot{\mathbf{x}} = \begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} \mathbf{x},\;\;\;\mathbf{x}(0) = \begin{bmatrix}
1\\
0
\end{bmatrix} $$


Now we know that the solution to this equation is $$\mathbf{x}(t) = e^{\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right)}\begin{bmatrix}
1\\
0
\end{bmatrix} = \exp\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right)\begin{bmatrix}
1\\
0
\end{bmatrix}$$

Now we need to compute $\exp\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right)$

$$\exp\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right) = \lim_{N \rightarrow \infty} \sum_{k=0}^{N}   \frac{\left(\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t\right)^k}{k!}\\
\Leftrightarrow \exp\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right) = \lim_{N \rightarrow \infty} \sum_{k=0}^{N}  \left(\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} \right)^k  \frac{t^k}{k!}$$

Note that $$\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} ^k =\left\{\begin{matrix}
\begin{bmatrix}
1 & 0\\
0 & 1
\end{bmatrix} , \text{if } k\mod{4} = 0\\\\
\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} , \text{if }k \mod{4}=1\\
\\
\begin{bmatrix}
-1 & 0\\
0 &  -1
\end{bmatrix}, \text{if } k \mod{4}=2\\\\
\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} , \text{if } k \mod{4} = 3
\end{matrix}\right.$$
where $n \mod k$ is the modulo operation.

Thus

$$\exp\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right) = \begin{bmatrix}
1 & 0\\
0 & 1
\end{bmatrix} + \begin{bmatrix}
0 & -t\\
t & 0
\end{bmatrix} + \begin{bmatrix}
-\frac{t^2}{2} & 0\\
0 & -\frac{t^2}{2}
\end{bmatrix} + \begin{bmatrix}
0 & \frac{t^3}{3!}\\
-\frac{t^3}{3!} & 0
\end{bmatrix} + \begin{bmatrix}
\frac{t^4}{4!} & 0\\
0 & \frac{t^4}{4!}
\end{bmatrix}+\begin{bmatrix}
0 & -\frac{t^4}{4!}\\
\frac{t^5}{5!} & 0
\end{bmatrix} + ...$$

$$\Leftrightarrow \exp\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right) = \begin{bmatrix}
1-\frac{t^2}{2}+\frac{t^4}{4!}+... & -t+\frac{t^3}{3!}-\frac{t^5}{5!}+ ...\\\\
t-\frac{t^3}{3!}+\frac{t^5}{5!}+... & 1-\frac{t^2}{2}+\frac{t^4}{4!} + ...
\end{bmatrix} $$

With a little effort you can recognize that

$$\cos(t) = 1-\frac{t^2}{2}+\frac{t^4}{4!}+...\\
\sin(t) = t-\frac{t^3}{3!}+\frac{t^5}{5!}+...\\$$

are the Taylor expansion of $\cos$ and $\sin$ function.Therefore we conclude that:

$$\exp\left (\begin{bmatrix}
0 & -1\\
1 &  0
\end{bmatrix} t \right) = \begin{bmatrix}
\cos(t) & -\sin(t)\\\\
\sin(t) & \cos(t)
\end{bmatrix} \\$$

$$\mathbf{x}(t) = \begin{bmatrix}
\cos(t) & -\sin(t)\\\\
\sin(t) & \cos(t)
\end{bmatrix}\begin{bmatrix}
1\\
0
\end{bmatrix} = \begin{bmatrix}
\cos(t)\\
\sin(t)
\end{bmatrix}$$

$\mathbf{x}(t)$ is the circle as the fig 1 suggested.