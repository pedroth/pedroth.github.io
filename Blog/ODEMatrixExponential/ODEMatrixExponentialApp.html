<header>
    <div class="container">
        <div class="row">
            <div class="col-lg-auto col-md-auto mx-auto">
                <div class="post-heading">
                    <h1>Differential Equations and Matrix exponential</h1>
                </div>
            </div>
        </div>
    </div>
</header>
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-auto col-md-auto mx-auto">
                In this post I would like to talk about simple differential equations in the euclidean space. Throughout this post let $n,m,k,N$ be integers. This is the problem of finding a function $\mathbf{x}:\mathbb{R}\rightarrow\mathbb{R}^n$ such that $\dot{\mathbf{x}}(t) = \frac{d \mathbf{x}}{dt} = \mathbf{g}(t,\mathbf{x})$. Which is the same as
                $$\dot{\mathbf{x}} = \begin{bmatrix}\dot{x}_1\\ ...\\ \dot{x}_n\end{bmatrix} = \begin{bmatrix}

            </div>
        </div>
    </div>
</article>


g_1(t,x_1,...,x_n)\\...
\\ g_n(t,x_1,...,x_n)
\end{bmatrix} \;\;\;\;(1)$$
We have already seen some differential equations in the <a href="http://pedroth.github.io/visualExperiments/Blog/TaylorPolynomial/TaylorPolynomial.html">Taylor</a> and <a href="http://pedroth.github.io/visualExperiments/Blog/IntuitionOfCalculus/IntuitionOfCalculus.html">differential calculus</a> posts. If we simplify (1) we can easily solve it. Suppose we have the following equation $$\dot{\mathbf{x}}(t) = \mathbf{g}(t)\,\,\;\;\;\;(2)$$<br />
<br />
To solve it you just need to use the fundamental theorem of calculus, like this:<br />
&nbsp;$$\mathbf{x}(t) = \mathbf{x}(0) + \int_0^{t} \dot{\mathbf{g}}(\tau) \,d\tau\;\;\;\;(3)$$<br />
<br />
or if you want a more analytical expression, you could use the same approach as&nbsp;<a href="http://pedroth.github.io/visualExperiments/Blog/TaylorPolynomial/TaylorPolynomial.html">Taylor</a>&nbsp;polynomial post:<br />
Suppose we could compute all the derivatives at a point, then by using (3) we get:<br />
&nbsp;$$\mathbf{x}(t) = \mathbf{x}(0) + \int_0^{t} \dot{\mathbf{g}}(\tau) \,d\tau$$<br />
<br />
note that $$\int_0^{t} \dot{\mathbf{g}}(\tau) \,d\tau = \begin{bmatrix}<br />
\int_0^t \dot{g_1}(\tau)d\tau\\<br />
...\\<br />
\int_0^t \dot{g_n}(\tau)d\tau<br />
\end{bmatrix}$$<br />
<br />
And finally the Taylor polynomial<br />
<br />
$$\mathbf{x}(t) = \mathbf{x}(0) + \int_0^{t} \dot{\mathbf{g}}(0) \,d\tau + \int_0^t\int_0^\tau\ddot{\mathbf{g}}(0) d\tau_2 \;+...$$<br />
$$\mathbf{x}(t) = \mathbf{x}(0) + \sum_{k=1}^{\infty} \frac{d^{(k)}\mathbf{g}(0)}{dt} \frac{t^k}{k!}\;\;\;\;(4)$$<br />
<br />
Now we have two ways to find a solution for (2), but what about (1)? In this post I will just solve a simpler version of (1), which is the following:<br />
<br />
$$\dot{\mathbf{x}} = &nbsp;M \mathbf{x}\;\;,\;\mathbf{x}(0) = \mathbf{x}_0\;\;\;\;(5)$$<br />
<br />
where $M \in \mathbb{R}^{n\times n}$ is a n by n matrix. In order to solve (4) we will use the Taylor polynomial approach since we can not use (3) approach because (5) depends on $\mathbf{x}$ and $t$ and not only on $t$.<br />
<br />
$$\frac{d\mathbf{x}}{dt} = M \mathbf{x}$$<br />
$$\frac{d^2\mathbf{x}}{dt} = M \frac{d\mathbf{x}}{dt} = M^2 \mathbf{x}$$<br />
$$...$$<br />
$$\frac{d^k\mathbf{x}}{dt} = M^k \mathbf{x}\;\;\;\;(6)$$<br />
<br />
Using the initial condition $\mathbf{x}(0) = \mathbf{x}_0$, (6) and (4) we get the solution.<br />
$$\mathbf{x}(t) =&nbsp;\sum_{k=0}^{\infty} \frac{d^{(k)}\mathbf{x}(0)}{dt} \frac{t^k}{k!}$$<br />
$$\Leftrightarrow&nbsp;\mathbf{x}(t) &nbsp;= &nbsp;\sum_{k=0}^{\infty} M^k \mathbf{x}_0 \frac{t^k}{k!}$$<br />
$$\Leftrightarrow \mathbf{x}(t) &nbsp;= &nbsp;\left (\lim_{N \rightarrow \infty} \sum_{k=0}^{N} &nbsp; \frac{(M t)^k}{k!}\right )\mathbf{x}_0\;\;\;\;(7)$$<br />
<br />
And finally we have a way to compute $\mathbf{x}(t)$, (In order to compute we must choose $N$ high enough such that the sum converges).<br />
<br />
To study this function little bit further, I will solve it using yet another technique, the <a href="http://en.wikipedia.org/wiki/Euler_method?oldformat=true">Euler method</a>. To explain the Euler method we need to see (5) as a vector field shown in fig 1 and 2.<br />
<br />
<table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody>
<tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-xyzfeDckAgk/VQQ2I5zCTfI/AAAAAAAAATg/W1zQVV0efIU/s1600/Numerozinho_15.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="400" src="https://4.bp.blogspot.com/-xyzfeDckAgk/VQQ2I5zCTfI/AAAAAAAAATg/W1zQVV0efIU/s640/Numerozinho_15.jpg" width="640" /></a></td></tr>
<tr><td class="tr-caption" style="text-align: center;">fig 1</td></tr>
</tbody></table>
<br />
<table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody>
<tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-A__n89eCuFY/VQQ2M3-qs7I/AAAAAAAAATo/e1Ig2WMwfw0/s1600/Numerozinho_16.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="400" src="https://3.bp.blogspot.com/-A__n89eCuFY/VQQ2M3-qs7I/AAAAAAAAATo/e1Ig2WMwfw0/s640/Numerozinho_16.jpg" width="640" /></a></td></tr>
<tr><td class="tr-caption" style="text-align: center;">fig 2</td></tr>
</tbody></table>
A vector field is a function $\mathbf{F}(\mathbf{x})$ that attributes at each point in the space a vector. For instance our differential equation (5) can be seen as vector field $\mathbf{F}(\mathbf{x}) = M \mathbf{x}$.<br />
<br />
e.g: $$\dot{\mathbf{x}} = \begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} \mathbf{x}$$ is the vector field on fig 1.<br />
<br />
Now we are ready to solve (5) using the Euler method. The Euler method is a simple method which one could derive just by looking to fig 2. We start at an initial position $\mathbf{x}_0$ then we compute the tangent vector to the curve by computing the vector field function, after that we find the next position by following the tangent vector by a step $h&gt;0$. This translates in the following iteration.<br />
$$\mathbf{x}(t_0) = \mathbf{x}_0\\<br />
\mathbf{x}(t + h) = \mathbf{x}(t) + h\mathbf{F}(\mathbf{x}(t))\;\;\;\;(8)$$<br />
<br />
Using (8) in our simple ODE(ordinary differential equation) (5), we get<br />
<br />
$$\mathbf{x}(t+h) = \mathbf{x}(t) + h M\mathbf{x}(t)\\<br />
\Leftrightarrow &nbsp; \mathbf{x}(t+h) = (I + h M)\mathbf{x}(t) \\$$<br />
<br />
$$\mathbf{x}(t_0) = \mathbf{x}_0$$<br />
$$\mathbf{x}(t_0 + h) = (I + h M)\mathbf{x}_0$$<br />
$$\mathbf{x}(t_0 + 2h) = (I + h M)\mathbf{x}(t_0+h) = (I + h M)^2\mathbf{x}_0$$<br />
$$...$$<br />
$$\mathbf{x}(t_0 + nh) = (I + h M)^n\mathbf{x}_0\;\;\;(8.25)$$<br />
<br />
This method is simple but comes with great cost, which is the error of the curve varies with $h$ (as $h$ increases the error increases), as you can see in fig 2 (red curve). In the limit of $h\rightarrow 0$ the curve generated by the Euler method converges to solution of the ODE.<br />
Let $t = t_0 + nh$, where $n$ is the number of samples. Then $h = \frac{t - t_0}{n}$<br />
<br />
From (8.25) and substituting $h$:<br />
<br />
$$\mathbf{x}(t) = \lim_{n\to \infty}\left (I + \left (\frac{t-t_0}{n}\right )M \right )^{n}\mathbf{x}_0\;\;\;(8.5)$$<br />
<br />
Let $t_0 = 0,\;\; t = 1$ ,(8.5) becomes :<br />
<br />
$$\mathbf{x}(t) =\lim_{n\to \infty}\left (I + \left (\frac{1}{n}\right )M\right )^n\mathbf{x}_0$$<br />
<br />
We can now define the matrix exponential as :<br />
<br />
$$e^{M} = &nbsp;\lim_{n\to \infty}\left (I + \left (\frac{1}{n}\right )M\right )^n$$<br />
<br />
From (7) and (8) we can conclude that solution of (5) is<br />
$$\mathbf{x}(t) = \left( \lim_{N \rightarrow \infty} \sum_{k=0}^{N} &nbsp; \frac{(M (t-t_0))^k}{k!}\right)\mathbf{x}_0$$<br />
$$\Leftrightarrow \mathbf{x}(t) = &nbsp;\lim_{n \to \infty}\left (I + \left (\frac{t-t_0}{n}\right )M\right )^{n}&nbsp;\mathbf{x}_0$$<br />
<br />
With the argument above we define the exponetial function as:<br />
<br />
$$\exp\left (M(t-t_0), \mathbf{x_0} \right ) = &nbsp;e^{M(t-t_0)}\mathbf{x}_0 = \mathbf{x}(t)$$</div>
<div>
<br /></div>
<div>
The solution to (5) is :</div>
<div>
<br />
$$\mathbf{x}(t) = &nbsp;e^{Mt} \mathbf{x}_0$$<br />
<br />
Note that $t_0 = 0$ in (5).<br />
<br />
To conclude lets check an example:<br />
I will use fig 1 example which is $$\dot{\mathbf{x}} = \begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} \mathbf{x},\;\;\;\mathbf{x}(0) = \begin{bmatrix}<br />
1\\<br />
0<br />
\end{bmatrix} $$<br />
<br />
<br />
Now we know that the solution to this equation is $$\mathbf{x}(t) = e^{\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right)}\begin{bmatrix}<br />
1\\<br />
0<br />
\end{bmatrix} = \exp\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right)\begin{bmatrix}<br />
1\\<br />
0<br />
\end{bmatrix}$$<br />
<br />
Now we need to compute $\exp\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right)$<br />
<br />
$$\exp\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right) = \lim_{N \rightarrow \infty} \sum_{k=0}^{N} &nbsp; \frac{\left(\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t\right)^k}{k!}\\<br />
\Leftrightarrow \exp\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right) = \lim_{N \rightarrow \infty} \sum_{k=0}^{N} &nbsp;\left(\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} \right)^k &nbsp;\frac{t^k}{k!}$$<br />
<br />
Note that $$\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} ^k =\left\{\begin{matrix}<br />
\begin{bmatrix}<br />
1 &amp; 0\\<br />
0 &amp; 1<br />
\end{bmatrix} , \text{if } k\mod{4} = 0\\\\<br />
\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} , \text{if }k \mod{4}=1\\<br />
\\<br />
\begin{bmatrix}<br />
-1 &amp; 0\\<br />
0 &amp; &nbsp;-1<br />
\end{bmatrix}, \text{if } k \mod{4}=2\\\\<br />
\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} , \text{if } k \mod{4} = 3<br />
\end{matrix}\right.$$<br />
where $n \mod k$ is the <a href="http://en.wikipedia.org/wiki/Modulo_operation">modulo operation</a>.<br />
<br />
Thus<br />
<br />
$$\exp\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right) = \begin{bmatrix}<br />
1 &amp; 0\\<br />
0 &amp; 1<br />
\end{bmatrix} + \begin{bmatrix}<br />
0 &amp; -t\\<br />
t &amp; 0<br />
\end{bmatrix} + \begin{bmatrix}<br />
-\frac{t^2}{2} &amp; 0\\<br />
0 &amp; -\frac{t^2}{2}<br />
\end{bmatrix} + \begin{bmatrix}<br />
0 &amp; \frac{t^3}{3!}\\<br />
-\frac{t^3}{3!} &amp; 0<br />
\end{bmatrix} + \begin{bmatrix}<br />
\frac{t^4}{4!} &amp; 0\\<br />
0 &amp; \frac{t^4}{4!}<br />
\end{bmatrix}+\begin{bmatrix}<br />
0 &amp; -\frac{t^4}{4!}\\<br />
\frac{t^5}{5!} &amp; 0<br />
\end{bmatrix} + ...$$<br />
<br />
$$\Leftrightarrow \exp\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right) = \begin{bmatrix}<br />
1-\frac{t^2}{2}+\frac{t^4}{4!}+... &amp; -t+\frac{t^3}{3!}-\frac{t^5}{5!}+ ...\\\\<br />
t-\frac{t^3}{3!}+\frac{t^5}{5!}+... &amp; 1-\frac{t^2}{2}+\frac{t^4}{4!} + ...<br />
\end{bmatrix} $$<br />
<br />
With a little effort you can recognize that<br />
<br />
$$\cos(t) = 1-\frac{t^2}{2}+\frac{t^4}{4!}+...\\<br />
\sin(t) = t-\frac{t^3}{3!}+\frac{t^5}{5!}+...\\$$<br />
<br />
are the Taylor expansion of $\cos$ and $\sin$ function.Therefore we conclude that:<br />
<br />
$$\exp\left (\begin{bmatrix}<br />
0 &amp; -1\\<br />
1 &amp; &nbsp;0<br />
\end{bmatrix} t \right) = \begin{bmatrix}<br />
\cos(t) &amp; -\sin(t)\\\\<br />
\sin(t) &amp; \cos(t)<br />
\end{bmatrix} \\$$<br />
<br />
$$\mathbf{x}(t) = \begin{bmatrix}<br />
\cos(t) &amp; -\sin(t)\\\\<br />
\sin(t) &amp; \cos(t)<br />
\end{bmatrix}\begin{bmatrix}<br />
1\\<br />
0<br />
\end{bmatrix} = \begin{bmatrix}<br />
\cos(t)\\<br />
\sin(t)<br />
\end{bmatrix}$$<br />
<br />
$\mathbf{x}(t)$ is the circle as the fig 1 suggested.</div>
