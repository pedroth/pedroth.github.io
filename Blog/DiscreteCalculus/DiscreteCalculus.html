<html>
<head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NQKJHP3');</script>
<!-- End Google Tag Manager -->
    <style>
        #experimentsTab {
        display: none
        }

        #projectTitle {
        color : rgb(255,255,255)
        }

        #header{
        background: #212121;
        background: -moz-linear-gradient(top, #373737, #212121);
        background: -webkit-linear-gradient(top, #373737, #212121);
        background: -ms-linear-gradient(top, #373737, #212121);
        background: -o-linear-gradient(top, #373737, #212121);
        background: linear-gradient(top, #373737, #212121);
        }

        #footer{
        background: #212121;
        background: -moz-linear-gradient(top, #373737, #212121);
        background: -webkit-linear-gradient(top, #373737, #212121);
        background: -ms-linear-gradient(top, #373737, #212121);
        background: -o-linear-gradient(top, #373737, #212121);
        background: linear-gradient(top, #373737, #212121);
        color: #fff;
        padding: 50px 10px 5px 10px;
        }

        #main_content{
            padding-right: 1px;
            padding-left: 1px;
        }

        .tr-caption-container {
            margin-top: 10px;
            margin-bottom: 10px;
        }
    </style>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="VisualExperiments : ">
    <script type="text/x-mathjax-config">
	  	MathJax.Hub.Config({
	    extensions: ["tex2jax.js"],
	    jax: ["input/TeX", "output/HTML-CSS"],
	    tex2jax: {
	      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
	      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
	      processEscapes: true
	    },
	    "HTML-CSS": { availableFonts: ["TeX"] }
	  });
    </script>

    <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/solid.js" integrity="sha384-tzzSw1/Vo+0N5UhStP3bvwWPq+uvzCMfrN1fEFe+xBmv1C/AtVX5K0uZtmcHitFZ" crossorigin="anonymous"></script>
    <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/fontawesome.js" integrity="sha384-6OIrr52G08NpOFSZdxxz1xdNSndlD4vdcf/q2myIUVO0VsqaGHJsB0RaBE01VTOY" crossorigin="anonymous"></script>
    <!-- MathJax -->
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
            type='text/javascript'></script>
    <!-- Jquery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.2/jquery.min.js"></script>
    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-select/1.11.2/css/bootstrap-select.min.css">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-select/1.11.2/js/bootstrap-select.min.js"></script>
</head>
<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NQKJHP3"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div id="header" class="jumbotron text-center">
    <a href="https://pedroth.github.io/visualExperiments/"><h1 id="projectTitle">VisualExperiments</h1></a>
    <ul class="list-inline">
        <li>
            <h3><a href="javascript:void(0)" id="experimentsName">Experiments</a></h3>
        </li>
        <li><h3><a href="https://pedroth.github.io/visualExperiments/Blog/Blog.html">Blog</a></h3></li>
        <li><h3><a href="https://www.youtube.com/user/peterluigi/">Youtube</a></h3></li>
        <li><h3><a href="https://www.khanacademy.org/profile/pedroth/programs">Khan Academy</a></h3></li>
    </ul>
    <div>
        <ul class="list-inline" id="experimentsTab">
            <li><h3><a href="https://pedroth.github.io/visualExperiments/JsExperiments/JsExperiments.html">
                JsExperiments </a></h3></li>
            <li><h3><a href="https://pedroth.github.io/visualExperiments/JavaExperiments/JavaExperiments.html">
                JavaExperiments </a></h3></li>
        </ul>
    </div>
    <script> $("#experimentsName").click( function() { $("#experimentsTab").slideToggle();})</script>
</div>

<div class="container">


<h1>DiscreteCalculus</h1>
<header>
    <div class="container">
        <div class="row">
            <div class="col-lg-auto col-md-auto mx-auto">
                <div class="post-heading">
                    <h1>Discrete Calculus</h1>
                </div>
            </div>
        </div>
    </div>
</header>
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-auto col-md-auto mx-auto">
                <h2> Intro </h2>

                In this post, we want to study sequences. Sequences are functions of the form $f: n \in
                \mathbb{N}\rightarrow s \in \mathbb{R}$, since $\mathbb{N}$ is a discrete space we can't apply the same
                rules of differential calculus to sequences.
                Here we will try to build a discrete version of the continuous calculus using the same principles. We
                will follow the same ideas of the previous posts, namely the <a
                    href="http://pedroth.github.io/visualExperiments/Blog/IntuitionOfCalculus/IntuitionOfCalculus.html"
                    target="_blank">intuition of calculus</a> and the <a
                    href="http://pedroth.github.io/visualExperiments/Blog/TaylorPolynomial/TaylorPolynomial.html"
                    target="_blank">Taylor polynomial</a> ( in this discrete setting it is actually called Newton
                polynomial ).

                <h2> Discrete Derivative </h2>

                Let us look at the following sequence:

                $$1,3,5,7,9,\dots$$

                Can you predict the next in the sequence? </br>
                Well if we have a formula that describes this sequence it should be easy, so let's find it out. It is
                easy to see that $f(n+1) - f(n) = 2$ for all numbers we see in the sequence. Assuming this property
                continues, we can construct the function using this difference.

                $$f(n+1) - f(n) = 2$$
                $$f(n+1)= f(n) + 2$$

                We know that $f(4) = 9$, hence $f(5) = 9 + 2$, but what about $f(1000)$. Assuming the same pattern on
                all the sequence we can find $f(n)$ for every $n > 0$.

                Starting from $n = 0$:

                $$f(0) = 1$$
                $$f(1) = f(0) + 2$$
                $$f(2) = f(1) + 2 = f(0) + 2 + 2$$
                $$f(3) = f(2) + 2 = f(1) + 2 + 2 = f(0) + 3 \times 2$$
                $$\dots$$
                $$f(n) = f(0) + 2n$$

                By applying this formula we find that the next element in the sequence is $f(1000) = 1 + 2 \times 1000 =
                2001$. This technique can be applied to any sequence. So let's do that! But first, let us make one
                useful definition.

                <h4>Definition 1</h4>

                Discrete derivative:

                $$\Delta f (n) = f(n+1) - f(n)$$

                The discrete derivative defined here is just the forward difference. We could have defined any other
                difference as a derivative, like the backward difference or the weighted difference.
                In the continuous case, all those generalizations of differences would converge to the derivative under
                the limit procedure, but in the discrete case we don't have such procedure, hence I will stick with this
                definition.<br><br>

                So how do we construct a sequence using just it's differences? Look at the following steps:

                $$f(0) = f(0)$$
                $$f(1) = f(0) + \Delta f(0)$$
                $$f(2) = f(1) + \Delta f(1) = [f(0) + \Delta f(0)] + \Delta f(1)$$
                $$f(3) = f(2) + \Delta f(2) = [f(1) + \Delta f(1)] + \Delta f(2) = [f(0) + \Delta f(0)] + \Delta f(1) +
                \Delta f(2)$$
                $$\dots$$
                $$f(n) = f(0) +\sum _{i= 0}^{n-1} \Delta f(i) \;\;\;\; (1)$$

                But (1) is just the fundamental theorem of calculus in the discrete setting:

                $$\sum _{i= 0}^{n-1} \Delta f(i) = f(n) - f(0)$$

                In the discrete theorem, we replaced the integral with the summation. Now we can see that the first
                sequence has the property that for every $n > 0$, $\Delta f(n) = 2$.
                Actually if we assume that a particular sequence has such property, $\forall n > 0, \Delta f(n) = \Delta
                f(0)$ we would get the linear approximation of the sequence around $n=0$.
                We just need to apply the fundamental theorem of discrete calculus using this assumption, and you would
                get such approximation, like in the continuous calculus:

                $$f(n) = f(0) +\sum _{i= 0}^{n-1} \Delta f(i) \simeq f(0) +\sum_{i= 0}^{n-1} \Delta f(0) = f(0) + \Delta
                f(0) n$$

                This approximation would be great for the first few numbers but then it would collapse under its error
                as $n \rightarrow \infty$.<br><br>

                <h2> Discrete Taylor/Newton series </h2>

                This reminds me of the <a
                    href="http://pedroth.github.io/visualExperiments/Blog/TaylorPolynomial/TaylorPolynomial.html"
                    target="_blank">Taylor
                polynomial article</a>, therefore we could apply the same techniques and see where we go. Starting from
                (1) we have:

                $$f(n) = f(0) +\sum _{i= 0}^{n-1} \Delta f(i)$$

                We can apply the same theorem to $\Delta f(n)$

                $$\Delta f(n) = \Delta f(0) +\sum _{i= 0}^{n-1} \Delta(\Delta f(i))$$

                Substituting on (1):

                $$f(n) = f(0) +\sum _{i= 0}^{n-1} \left [ \Delta f(0) + \sum _{j= 0}^{i-1} \Delta^{(2)}f(j) \right ] =
                f(0) + \sum _{i= 0}^{n-1} \Delta f(0) + \sum _{i= 0}^{n-1} \sum _{j= 0}^{i-1} \Delta^{(2)}f(j)\;\;\;\;
                (2)$$

                Here we see one new concept, the concept of the second derivative $\Delta(\Delta f(n)) =
                \Delta^{(2)}f(n)$. Which leads me to the second definition:

                <h4>Definition 2</h4>
                Discrete kth derivative:

                $$\Delta^{(k)} f(n) = \Delta^{(k-1)}f(n+1) - \Delta^{(k-1)}f(n)$$

                This definition follows from applying the derivative operator multiple times, e.g:

                $$\Delta^{(2)}f(n) = \Delta(\Delta f(n)) = \Delta f(n+1) - \Delta f(n) = [f(n+2) - f(n+1)] - [f(n + 1) +
                f(n)] $$

                We can expand (2) little further by doing the same thing for $\Delta^{(2)}f(j)$ and so on:

                $$f(n) = f(0) + \sum _{i= 0}^{n-1} \Delta f(0) + \sum _{i= 0}^{n-1} \sum _{j= 0}^{i-1} \Delta^{(2)}f(0)
                + \sum _{i=
                0}^{n-1} \sum _{j= 0}^{i-1}\sum_{k=0}^{j-1}\Delta^{(3)}f(0) + \dots\;\;\;\; (3)$$

                Now we have an explicit formula for $f$ in terms of the differentials, but this is a horrible formula.
                Can we
                simplify it?

                In order to simplify we need to compute:
                $$\Delta f(0)\sum_{i_1 = 0}^{n-1} 1$$
                $$\dots$$
                $$\Delta^{(k)}f(0)\sum_{i_1 = 0}^{n-1} \dots \sum_{i_k = 0}^{i_{k-1} - 1}1$$

                To simplify the notation I define:
                $$\Psi(n,k) = \sum_{i_1 = 0}^{n-1} \dots \sum_{i_k = 0}^{i_{k-1} - 1}1$$

                Then (3) becomes:
                $$f(n) = f(0) + \Delta f(0) \Psi(n,1) + \dots + \Delta^{(k)}f(0)\Psi(n,k)+ \dots \;\;\; (4)$$

                In the continuous calculus we had a similar problem, the Taylor expansion at $x_0=0$ was given by:
                $$f(x) = \sum_{k=0}^{\infty}\frac{d^{(k)}f(0)}{dx^k}\Omega(x,k)$$
                Where $$\Omega (x,k) = \int_{0}^{x} ... \int_{0}^{u_{k-1}}1du_k...du_1$$

                And this is easier than the discrete setting since we have nice closed formulas to compute integrals. In
                that post we found that:

                $$\Omega(x,k) = \frac{x^k}{k!}$$

                But what what about the discrete case? We have to do the same thing. We know that:
                $$\Psi(n,k) = \sum_{i_1=0}^{n-1}\left [\sum_{i_2=0}^{i_1-1}...\sum_{i_k=0}^{i_{k-1}-1} 1\right]=
                \sum_{i_1=0}^{n-1}\Psi(i_1,k-1)$$

                Then by the fundamental theorem of discrete calculus and knowing that $\Psi(0,k) = 0, k > 0$ we get:
                $$\Psi(n,k) = \sum_{i_1=0}^{n-1} \Delta \Psi(i_1, k) = \sum_{i_1=0}^{n-1}\Psi(i_1,k-1)$$
                Hence,
                $$\Delta \Psi(n,k) = \Psi(n,k-1)\;\;\;\;(5)$$

                So from (5) we find the next recursion:
                $$\Psi(n+ 1, k) - \Psi(n,k) = \Psi(n,k-1) \;\;\;\; (6)$$
                $$ \Psi(n+ 1, k) = \Psi(n,k) + \Psi(n,k-1)$$

                Note that $\Psi(n,1) = \sum_{i_1=0}^{n-1}1 = \sum_{i_1=0}^{n-1} \Psi(n,0)$, hence $\Psi(n,0) = 1 \;
                \forall n\geq 0$. We can also check that $\Psi(0,k) = 0 \;\forall k > 0$, by its definition. So using the recursion (6) and all of these facts we can compute $\Psi$ as follows:

                $$\Psi(n,k) = \begin{cases}
                0\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\text{ if } n = 0
                \text{ and
                } k > 0\\
                1 \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\text{ if } n
                \geq 0 \text{ and
                } k=0\\
                \Psi(n-1,k) + \Psi(n-1,k-1)\;\;\text{ if } n > 0 \text{ and } k > 0\\
                0\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\text{ otherwise}
                \end{cases}$$

                This expression is good for computers but not for humans, hence we need to find another way. Lets check
                a sequence of $\Psi(n,k)$ values and see if we find some pattern:
                $$\Psi(n,1) = \sum_{i_1=0}^{n-1}1 = n$$
                $$\Psi(n,2) = \sum_{i_1=0}^{n-1}\sum_{i_2=0}^{i_1-1}1 = \sum_{i_1=0}^{n-1}i_1$$

                How do you compute $\sum_{i_1=0}^{n-1}i_1$ ? <br><br>

                We know by the fundamental theorem of discrete calculus that if we find a function $g$, such that
                $\Delta g(n) = n$ and $g(0) = 0$, then $g(n) = \sum_{i_1=0}^{n-1}\Delta g(i_1) = \sum_{i_1=0}^{n-1}
                i_1$.<br>
                Let's try $g(n) = n^2$. By definition:
                $$\Delta g(n) = (n+1)^2 - n^2 = 2n + 1$$

                Not quite what we want. We need more tools.<br><br>

                It is simple to proof that:
                $$\Delta(f + g)(n) = \Delta f(n) + \Delta g(n)$$
                And
                $$\Delta(c f)(n) = c \Delta f(n)$$

                <button class="btn btn-primary" onclick='$("#proof_1").slideToggle()'><h4>Proof</h4></button>
                <div id="proof_1" style="display:none">
                    $$\Delta(f(n) + g(n)) = [f(n+1) + g(n+1)] - [f(n) + g(n)] = f(n+1)-f(n) + g(n+1)-g(n) = \Delta f(n)
                    + \Delta g(n)$$

                    and

                    $$\Delta(c f(n)) = [cf(n+1)] - [cf(n)] = c (f(n+1) - f(n)) = c \Delta f(n)$$
                </div>
                <br><br>

                Using these tools and trial and error, I get the following expression:
                $$\Delta \left( \frac{n^2}{2} - \frac{n}{2} \right ) = \frac{\Delta(n^2)}{2} - \frac{\Delta(n)}{2}$$
                $$ \frac{2n + 1}{2} - \frac{1}{2} = n$$
                Thus:
                $$\Psi(n, 2) = \sum_{i_1=0}^{n-1}i_1 = \frac{n^2 - n}{2} =\frac{n(n-1)}{2}$$

                We could continue to guess $\Psi(n, 3)$, and then check if $\Delta \Psi(n, 3) = \frac{n(n-1)}{2}$, but I
                find this way to difficult to proceed.
                Instead I will try and check some new pattern. We have until now:
                $$\Psi(n,0) = 1$$
                $$\Psi(n,1) = n = n[1]$$
                $$\Psi(n,2) = \frac{n(n-1)}{2} = \frac{n-1}{2}[n][1]$$
                I guess that $\Psi(n,3)$ will be:

                $$\Psi(n,3) = \frac{(n-2)}{3}\left [\frac{n(n-1)}{2} \right]$$

                It seems to me that $\Psi(n, k) = \frac {n -(k-1)}{k} \Psi(n, k-1)$. Using this hypothesis we find:

                $$\Psi(n, k) = \frac {n -(k-1)}{k} \Psi(n, k-1) = \frac {n -(k-1)}{k} \left [ \frac {n -(k-2)}{k-1}
                \Psi(n, k-2)\right]$$
                $$\Psi(n, k) = \frac {n -(k-1)}{k} \left [ \frac {n -(k-2)}{k-1} \Psi(n, k-2)\right] = \dots = \frac {n
                -(k-1)}{k} \dots \frac {n -(k - k)}{k - (k - 1)} = \frac{(n - (k - 1))(n - (k - 2)) \dots n}{k (k-1)
                \dots 1}$$
                $$\Psi(n, k) = \frac{n(n - 1)(n - 2) \dots (n - (k - 1))}{k!}$$

                Let us check if this hypothesis is correct:

                $$\Psi(n,k) = \Psi(n-1,k) + \Psi(n-1,k-1)$$
                Substituting with our conjecture:
                $$\Leftrightarrow \Psi(n,k) = \frac{(n-1)(n-2)...(n-k)}{k!} + \frac{(n-1)(n-2)...(n-k+1)}{(k-1)!}$$
                $$\Leftrightarrow \Psi(n,k) = \frac{(n-1)(n-2)...(n-k)}{k!} + \frac{k(n-1)(n-2)...(n-k+1)}{k(k-1)!}$$
                $$\Leftrightarrow \Psi(n,k) = \frac{(n-1)(n-2)...(n-k+1)(n-k) + (n-1)(n-2)...(n-k+1)k}{k!}$$
                $$\Leftrightarrow \Psi(n,k) = \frac{\left [(n-1)(n-2)...(n-k+1)\right]((n-k)+ k)}{k!}$$
                $$\Leftrightarrow \Psi(n,k) = \frac{\left [(n-1)(n-2)...(n-k+1)\right]n}{k!} = \Psi(n,k)$$

                With this argument, we conclude that our conjecture is indeed the function $\Psi$. It's important to
                note what we did here. We assumed that the ratio of neighbour values of $\Psi$ had a specific formula,
                $\frac{\Psi(n,k)}{\Psi(n, k-1)} = \frac{n - k + 1}{k}$, then we derived $\Psi$ using that assumption.
                If you watch closely, you will notice the similarity with the discrete derivative, but instead of taking
                the difference of neighbor values we divide. This technique made me think that we can define other
                calculus and find some nice theorems. Maybe in a future post, we can explore a multiplicative calculus
                (discrete and continuous).<br><br>

                Just to be completely sure (that we didn't make any mistake in the derivation of $\Psi$), I will make a
                little program that computes $\Psi$ using their three definitions, $\Psi_{\text{sum}}$,
                $\Psi_{\text{recursive}}$ and $\Psi_{\text{closed}}$. If they are equal then we didn't make a mistake (probably :D)

                <br><br>$n = $ <input type="number" min="0" id="nPsi" value="10">, $k = $ <input type="number" min="0"
                                                                                                 id="kPsi" value="3">
                <button class="btn btn-primary" onclick='app.showTable()'>Compute</button>
                <div id="psiComputeTable" style="display:none"></div>
                <br><br>

                From (4) and $\Psi$ we get the discrete Taylor series:

                $$f(n) = \sum_{k=0}^\infty \Delta^k f(0) \Psi(n, k) = \sum_{k=0}^\infty \Delta^k f(0) \frac{n\dots(n
                -(k-1))}{k!}$$

                Which is also called the Newton series. In order to simplify the formula, we define the failing
                factorial formula.

                <h4>Definition 3</h4>

                The failing factorial:

                $$n^{\underline{k}} = n \dots (n - (k - 1)) = \prod_{j=0}^{k-1} n - j$$

                Using definition 3, we simplify the discrete Taylor expansion to:

                $$f(n) = \sum_{k=0}^\infty \Delta^k f(0) \frac{n^{\underline{k}}}{k!} \;\;\; (7)$$

                Now that we find the discrete Taylor polynomial we can compare with the continuous one:

                $$f(n) = \sum_{k = 0}^\infty \Delta^k f(0) \frac{n^{\underline{k}}}{k!}, f(x) = \sum_{n=0}^\infty
                \frac{d^n f(0)}{dx^n} \frac{x^n}{n!}$$

                They are very similar, their major difference lies on the derivative they use. I would say that $\Delta^k
                f(0) \equiv \frac{d^n f}{dx^n}(0)$ and $\Psi \equiv \Omega$. Note that $\Psi$ and $\Omega$ are
                equivalent since both of them have the following property:

                $$\Delta \Psi(n, k) = \Psi(n, k - 1) \text{ and } \Omega'(x, k) = \Omega(x, k - 1)$$

                These similarities are amazing, but the infinity symbol on the discrete series is troubling me, I would
                expect the continuous version to have that but not the discrete. Fortunately there is one property about
                $\Psi$ that solves our issue, this property is $\Psi(n, k) = 0, k > n$. Thus (7) becomes:

                $$f(n) = \sum_{k=0}^n \Delta^k f(0) \frac{n^{\underline{k}}}{k!} \;\;\; (8)$$

                <button class="btn btn-primary" onclick='$("#proof_2").slideToggle()'><h4>Proof of property</h4>
                </button>
                <div id="proof_2" style="display:none"><br><br>

                    To prove that $\Psi(n, k) = 0, k > n$, we will use the technique called <a target="_blank"
                                                                                               href="https://en.wikipedia.org/wiki/Mathematical_induction">proof
                        by induction</a>.<br><br>

                    In order to use induction, I will transform the problem to an equivalent one:

                    $$\Psi(n, n + \varepsilon) = 0, \varepsilon > 0 $$

                    The base case, $n = 0$ is true by the definition of $\Psi$:

                    $$\Psi(0, \varepsilon) = 0$$

                    The inductive step is:

                    $$\Psi(n + 1, n + \varepsilon + 1) = \Psi(n, n + \varepsilon + 1) + \Psi(n, n + \varepsilon)$$

                    By the induction hypothesis we know that $\Psi(n, n + \varepsilon) = 0$. Also if $\varepsilon + 1 =
                    \eta$ then:

                    $$\Psi(n + 1, n + \varepsilon + 1) = \Psi(n, n + \eta)$$

                    We know by our hypothesis that $\Psi(n, n + \eta) = 0$, therefore $\Psi(n + 1, n + \varepsilon + 1)
                    = 0$.<br><br>

                    This finishes our proof. We can also check that this true by constructing $\Psi$ using a table.

                    <br><br>$n = $ <input type="number" min="0" id="nPsi2" value="10">, $k = $ <input type="number"
                                                                                                      min="0" id="kPsi2"
                                                                                                      value="11">
                    <button class="btn btn-primary" onclick='app.showTable2()'>Compute</button>
                    <div id="psiComputeTable2" style="display:none">
                    </div>
                </div>
                <br><br>

                <h2> Series Error </h2>

                The error of the series is $R_N(n) = \left |f(n) - \sum_{k=0}^N \Delta^k f(0) \Psi(n,k) \right|$, $N < n$. Following the same idea as the <a href="http://pedroth.github.io/visualExperiments/Blog/TaylorPolynomial/TaylorPolynomial.html" target="_blank">Taylor polynomial</a>, we get:

                $$R_N(n) = \left |f(n) - \sum_{k=0}^N \Delta^k f(0) \Psi(n,k) \right| = \left |\sum_{i_1 = 0}^{n - 1} \dots \sum_{i_{N+1}=0}^{i_{N}-1} \Delta^{N+1} f(i_{N+1})\right |$$

                We proceed as the other post and get an upper bound on the error:
                $$R_N(n) \leq \left |\sum_{i_1 = 0}^{n - 1} \dots \sum_{i_{N+1}=0}^{i_{N}-1} \Delta^{N+1} f(i_{N+1})\right | \leq \sum_{i_1 = 0}^{n - 1} \dots \sum_{i_{N+1}=0}^{i_{N}-1} |\Delta^{N+1} f(i_{N+1})| $$

                $$R_N(n) \leq \sum_{i_1 = 0}^{n - 1} \dots \sum_{i_{N+1}=0}^{i_{N}-1} |\Delta^{N+1} f(i_{N+1})| \leq \max_{c} |\Delta^{N+1} f(c)| \sum_{i_1 = 0}^{n - 1} \dots  \sum_{i_{N+1}=0}^{i_{N}-1} 1$$

                $$R_N(n) \leq \max_{c} |\Delta^{N+1} f(c)| \sum_{i_1 = 0}^{n - 1} \dots  \sum_{i_{N+1}=0}^{i_{N}-1} 1 \leq  \max_{c} |\Delta^{N+1} f(c)| \Psi(n,N+1)$$

                The formula is pretty similar to the continuous formula, thus we can infer some of the same conclusions as the continuous version. Now let us look at some applications.

                <h2> Applications </h2>

                <h3>Difference Equations</h3>

                Let us look into some applications, the simplest one is to solve a discrete differential equation also
                known as a difference equation. The one equation I will show is the discrete exponential equation:

                $$\Delta u = u, \; u(0) = 1$$

                Using the discrete Taylor expansion at zero we find that:

                $$u(n) = \sum_{k=0}^n \Delta^k u(0) \frac{x^{\underline{k}}}{k!}$$

                We just need to find $\Delta^k u$, but that is easy since $\Delta u = u$. It is easy to see that
                $\Delta^k u = u$, hence $\Delta ^k u(0) = u(0) = 1$, therefore we get:

                $$u(n) = \sum_{k=0}^n \frac{x^{\underline{k}}}{k!}$$

                Actually there is easier way to derive a closed form solution to this difference equation, note that:

                $$\Delta u(n) = u(n)$$
                $$u(n+1) - u(n) = u(n)$$
                $$u(n+1) = 2u(n)$$

                Starting from zero we get:

                $$u(1) = 2u(0)$$
                $$u(2) = 2u(1) = 2^2u(0)$$
                $$\dots$$
                $$u(n) = 2^n u(0) = 2^n$$

                Therefore we find out the following identity:

                $$u(n) = 2^n = \sum_{k=0}^n \frac{x^{\underline{k}}}{k!}$$

                I didn't mention before but $\frac{x^{\underline{k}}}{k!}$ is a formula for the number of <a
                    href="https://en.wikipedia.org/wiki/Combination" target="_blank"> combinations </a> in a set. It has
                the following notation:

                $$\binom{n}{k} = \frac{n!}{k!(n-k)!} = \frac{n \dots (n-k+1)}{k!} = \frac{n^{\underline{k}}}{k!}$$

                Using this notation we found one amazing combinatorial fact:

                $$u(n) = 2^n = \sum_{k=0}^n \binom{n}{k} $$

                The combinatorial fact is that, the number of all subsets of a set of size $n$ ( given by the formula $\sum_{k=0}^n \binom{n}{k}$)  is equal to $2^n$ ( see <a target="_blank" href="https://en.wikipedia.org/wiki/Power_set"> power set </a> for a different derivation).

                <h3>Interpolation of sequences</h3>

                Other application is interpolation of sequences. Imagine a sequence $f_0, \dots, f_{N-1}$, then we can make
                the Newton polynomial of this sequence:

                $$f(n) = \sum_{k=0}^n \Delta ^k f(0) \Psi(n, k)$$

                Since the $n$ in $\Psi$ doesn't need to be a integer, if we substitute $n \in {0, \dots, N-1}$ with $x \in [0, N-1]$, we automatically interpolate the sequence over $\mathbb{R}_+$.
                But there is still one problem here, we can't simply substitute $n$ by $x$ everywhere, at least not in the sum. If you remember, in (7) the sum was infinite, we simply reduced to $n$, because $\Psi(n,k) = 0, k > n$, thus in order to make this formula to work we will substitute the $\infty$ to something constant like $N-1$. The interpolating formula is:

                $$f(x \in \mathbb{R}) = \sum_{k=0}^{N-1} \Delta ^k f(0) \Psi(x, k)$$

                Remember that when $x < k$, $\Psi(x,k) = 0$, so the formula does work. Check simulation 1 for a demo.

                <br><br>
                <button class="btn btn-primary" onclick="app.run(0)"><h4> Simulation 1</h4></button>
                <div id="sim1" style="display:none; text-align: center">
                    <canvas id="interpolation" width="650" height="500"></canvas>
                    <div style="text-align: center;">
                        <button class="btn btn-primary" onclick="app.apply(0, x => x.nextRandomSeq())">Random Sequence
                        </button>
                        <button class="btn btn-primary" onclick="app.apply(0, x => x.increaseSeq())">+</button>
                        <button class="btn btn-primary" onclick="app.apply(0, x => x.decreaseSeq())">-</button>
                        <p>Simulation.1 Interpolate a sequence using the method above. You can interact with the canvas
                            (mouse | touch).</p>
                    </div>
                </div><br><br>

                If you played with simulation 1, you will notice that the polynomial becomes unstable as the number of samples increases, although the curve passes through the sequence points.
                It turns outs that interpolation of a function is a field on its own and thus needs to be handled in a different post.

                <h3>Taylor series from the Newton series</h3>

                My final application is to show that using the discrete Taylor series, we can deduce the continuous one.
                Suppose we have a function $f:x \in [a,b]\rightarrow\mathbb{R}$. Let $u:\{0, \dots, N-1\}\rightarrow\mathbb{R}$ be a sampling of $f$. Therefore $u$ is defined as $u(n) = f(a + hn)$ , where $h = \frac{b-a}{N-1}$ and $N$ is the number of samples.
                We know:

                $$u(n) = \sum_{k=0}^{N-1} \Delta^{k} u(0) \frac{n \dots (n-k+1)}{k!}$$

                Notice that here, the summation goes until $N-1$ instead of $n$, but this is a valid move since $n \leq N-1$ and $\Psi(n, k) = 0, k > n$ as said before. The $N-1$ is used in the sum because we want the sum to be independent of $n$ since we will substitute $n$ by $x$. But before that let us substitute $u$ by $f$.
                This is simple just notice that $u(n) = f(a + hn)$, hence:

                $$\Delta u(0) = u(1) - u(0) = f(a + h) - f(a) = \Delta_h f(a)$$

                Then we can derive that:

                $$\Delta^k u(0) = \Delta_h^k f(a) = \Delta_h^{k-1} f(a + h) - \Delta_h^{k-1} f(a)$$

                Now the formula becomes:

                $$u(n) = \sum_{k=0}^{N-1} \Delta_h^{k} f(a) \frac{n \dots (n-k+1)}{k!}$$

                The closest sample $n$ to some $x$ is given by solving $a + hn = x$, so:

                $$x = a + hn \Leftrightarrow n = \frac{x-a}{h}$$

                Substituting $n$ we get:

                $$u(x) = \sum_{k=0}^{N-1} \Delta_h^{k} f(a) \frac{\frac{x-a}{h} \dots \left( \frac{x - a}{h}-k+1 \right)}{k!}$$
                $$u(x) = \sum_{k=0}^{N-1} \Delta_h^{k} f(a) \frac{\frac{x-a}{h} \dots \left( \frac{x - a - h(k-1)}{h} \right)}{k!}$$
                $$u(x) = \sum_{k=0}^{N-1} \frac{\Delta_h^{k} f(a)}{h^k} \frac{(x-a) \dots (x - a - h(k - 1))}{k!}$$

                Now if we increase the number of samples to infinity ($N \rightarrow \infty$), $h$ will tend to zero since $h = \frac{b-a}{N-1}$ and $u(x)$ will become $f(x)$:

                $$f(x) = \lim_{N \rightarrow \infty}\sum_{k=0}^{N-1} \frac{\Delta_h^{k} f(a)}{h^k} \frac{(x-a) \dots (x - a - h(k - 1))}{k!} = \sum_{k=0}^{\infty} \frac{d^k f(a)}{dx^k} \frac{(x - a)^k}{k!} \;\;\;(9)$$

                This last equation (9) is the famous continuous Taylor polynomial.

                <h2> Conclusion </h2>

                In this post we found out a discrete calculus. While doing it, we discovered the discrete analogs of the fundamental theorem of calculus, the Taylor polynomial, and the exponential function.
                We also saw how the Newton series could be applied to interpolation and to derive the continuous Taylor polynomial, which let me think about this calculus being a more fundamental tool, than its continuous counterpart.
                In future posts, I would like to continue this adventure on discrete calculus, by exploring a multivariate discrete calculus, discrete differential geometry and so on.

            </div>
        </div>
    </div>
</article>
<script src="DiscreteCalculus.js"></script>

<!-- Disqus -->
<div id="disqus_thread"></div>
<script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'visualexperiments'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();


        </script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
    Disqus.</a></noscript>
</div>


<footer id="footer" class="container-fluid">
    <p class="copyright">VisualExperiments maintained by <a href="https://github.com/pedroth">pedroth</a></p>
    <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
</footer>
</body>
</html>


</html>
